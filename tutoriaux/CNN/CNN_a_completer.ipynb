{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p_5PWr7JoIbf"
   },
   "source": [
    "# ÉCOLE IVADO/MILA EN APPRENTISSAGE PROFOND\n",
    "# SESSION D' AUTOMNE 2018 \n",
    "# Tutoriel : Réseaux à convolutions\n",
    "\n",
    "## Auteurs: \n",
    "\n",
    "Margaux Luck <margaux.luck@rd.mila.quebec>\n",
    "\n",
    "Jeremy Pinto <jeremy.pinto@rd.mila.quebec>\n",
    "\n",
    "Mathieu Germain <mathieu.germain@rd.mila.quebec>\n",
    "\n",
    "## Préface\n",
    "\n",
    "Ce tutoriel à pour but d'introduire les concepts fondamentaux sur les réseaux de neurones à convolution à l'aide d'exemples concrets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A73O9J3necuk"
   },
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0PNXwEm-ej9a"
   },
   "source": [
    "Avant de commencer, nous devons nous assurer d'installer les librairies nécessaires pour le tutoriel à l'aide de `pip`.  Pour se faire, exécutez la cellufle suivante en la sélectionnant et en cliquant `shift`+`Enter`. Ceci peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNlYWG6z9GKT"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision Pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddGNnGb0lMFJ"
   },
   "source": [
    "Afin de vous assurer que l'installation s'est bien faite, importez toutes les libraries et modules dont nous nous servirons pour ce tutoriel en exécutant la prochaine cellule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfmCDK-xlRmW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"GPU Available: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNomSpLO9LeH"
   },
   "source": [
    "# Le jeu de données MNIST\n",
    "MNIST est le **jeu de données de référence de classification** utilisé en **vision par ordinateur**. Il est hébergé sur le <a href=\"http://yann.lecun.com/exdb/mnist/\">le site de Yann LeCun</a>. Il se compose d'**images de chiffres manuscripts**. Quelques exemples sont données ci-dessous :\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/mnist.png?raw=true)\n",
    "\n",
    "Il inclut également des **étiquettes de classes pour chaque image**, indiquant à quel chiffre elle correspond. Par exemple, les étiquettes des images ci-dessus sont 5, 0, 4 et 1.\n",
    "\n",
    "Il se compose de **60 000 exemples d'entraînement** et de **10 000 exemples de test**. Les images sont toutes de la même taille (**28x28 pixels**). Chaque pixel est représenté par un chiffre entre 0 et 255 indiquant une nuance de gris. En fonction des modèles que nous allons tester les images seront utilisées telles quelles ou bien aplaties.\n",
    "\n",
    "Les classes sont balancées, c'est à dire qu'il y a une proportion plus ou moins égale des différents chiffres dans notre jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk9AMaT9hmcX"
   },
   "source": [
    "## Objectif\n",
    "\n",
    "Nous cherchons à concevoir un algorithme pour classifier ces chiffres correctement. Dans notre cas, nous utiliserons comme entrée l'intensité de tous les pixels d'une image et essayerons de prédir la valeur du chiffre en question. Ce problème peut se résumer à:\n",
    "\n",
    "`f(image) = chiffre prédit`\n",
    "\n",
    "où `f` est une fonction quelconque. \n",
    "\n",
    "Dans ce tutoriel, nous considérerons un **perceptron multi-couche** ainsi qu'un **réseau de neuronnes à convolution**. Ces fonctions prennent en entrée l'intensité des pixels et effectuent des opérations mathématiques sur ces valeurs. La valeur de retour de la fonction est un vecteur de taille *1xN* où chaque entrée correspond à la probabilité que le chiffre en question soit ce chiffre. La somme de toutes ces valeurs est nécessairement de 1. Notre prédiction finale est l'entrée pour laquelle la probabilité est maximale. Par exemple, la prédiction\n",
    "\n",
    "`[0.8, 0.1, 0, 0, 0, 0.05, 0.05, 0.0, 0.0, 0.0, 0.0]`\n",
    "\n",
    "indique à 80% de chances qu'il s'agit du chiffre 0.\n",
    "\n",
    "Pour chacun de ces modèles, nous chercherons à \"apprendre\" la meilleure solution. Pour se faire, nous commencerons à partir d'une solution aléatoire et chercherons à converger vers une solution optimale. À chaque itération, nous comparons les résultats de notre prédiction à la réelle valeure et ajustons nos modèles par la suite jusqu'à ce que nous satisfaisons un certain critère d'arret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1U2sDz9ufy9"
   },
   "source": [
    "## Télécharger les données et créer le chargeur de données\n",
    "\n",
    "Avant de commencer, nous devons nous assurer d'avoir accès aux données de MNIST. Nous utiliserons les fonctions natives à PyTorch pour les récupérer.\n",
    "\n",
    "### Boîte à outils\n",
    "**Rappel:** Dans PyTorch, il existe des fonctions pour charger, mélanger et augmenter les données. \n",
    "\n",
    "Une façon simple de charger les données dans PyTorch est : \n",
    "<ul>\n",
    "<li>D'utiliser une classe enfant de <a href=\"http://pytorch.org/docs/master/data.html#torch.utils.data.Dataset\">`torch.utils.data.Dataset`</a> où les méthodes `__getitem__` et `__len__` sont à compléter.</li>\n",
    "<li>D'utiliser la classe <a href=\"http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader\">`torch.utils.data.DataLoader`</a> pour lire et mettre en mémoire les données.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Par chance, dans pytorch, il existe déjà une classe enfant de Dataset pour utiliser MNIST : <a href=\"http://pytorch.org/docs/master/torchvision/datasets.html#mnist\">`torchvision.datasets.MNIST`</a>.\n",
    "\n",
    "<a href=\"http://pytorch.org/docs/master/torchvision/datasets.html\">D'autres jeux de données sont aussi disponibles.</a>\n",
    "\n",
    "**Remarque:** <a href=\"http://pytorch.org/docs/master/tensors.html#torch.Tensor.view\">`torch.Tensor.view()`</a> renvoie un nouveau tenseur avec les mêmes données que le tenseur d'origine mais avec une taille différente. Cela peut donc être utilisé pour aplatir une image, par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2iC4F8H8bsx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import sampler, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "manualSeed = 1234\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# Fixing random seed\n",
    "random.seed(manualSeed)\n",
    "np.random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if use_gpu:\n",
    "   torch.cuda.manual_seed_all(manualSeed)\n",
    "\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset.\n",
    "    From: https://github.com/pytorch/vision/issues/168\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_samples: int\n",
    "      # of desired datapoints\n",
    "    start: int\n",
    "      Offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "train_dataset = MNIST(root='../data', \n",
    "                      train=True, \n",
    "                      transform=transforms.ToTensor(),  \n",
    "                      download=True)\n",
    "\n",
    "test_dataset = MNIST(root='../data', \n",
    "                     train=False, \n",
    "                     transform=transforms.ToTensor())\n",
    "\n",
    "train_dataset_sizes = len(train_dataset)\n",
    "num_train_samples = int(0.8 * train_dataset_sizes)\n",
    "num_valid_samples = train_dataset_sizes - num_train_samples\n",
    "num_test_samples = len(test_dataset)\n",
    "\n",
    "print('# of train examples: {}'.format(num_train_samples))\n",
    "print('# of valid examples: {}'.format(num_valid_samples))\n",
    "print('# of test examples: {}'.format(num_test_samples))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          sampler=ChunkSampler(num_train_samples, 0),\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False)\n",
    "\n",
    "valid_loader = DataLoader(dataset=train_dataset,\n",
    "                          sampler=ChunkSampler(\n",
    "                              num_valid_samples, num_train_samples),\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRV8zZbHV6zN"
   },
   "source": [
    "Visualisons les données d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TB57DZYzV9Oz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "print('Inputs size: {}'.format(inputs.size()))\n",
    "print('Classes size: {}'.format(classes.size()))\n",
    "\n",
    "# Random image of the batch\n",
    "img1 = 255 - inputs[np.random.randint(len(inputs))] * 255\n",
    "\n",
    "# Plot the image\n",
    "print('\\n\\nDisplay the first image:')\n",
    "img1 = img1.numpy()[0, :, :]\n",
    "plt.imshow(img1, cmap='gray', vmin=0, vmax=255)\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_XSUTbG0UvX"
   },
   "source": [
    "# CPU ou GPU\n",
    "**Rappel:** <a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> est une librairie qui permet d'utiliser des GPUs pour effectuer les calculs sur des tenseurs. La librairie inclus des tenseurs de type CUDA qui ont les mêmes fonctions que les tenseurs réguliers mais qui utilisent des GPUs pour leurs calculs, au lieu d'un CPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> retourne un booléen indiquant si CUDA est présentement disponible. Pour passer d'un tenseur de type CPU à un tenseur de type GPU, il suffit de lui ajouter `.to(\"cuda:0\")`.\n",
    "\n",
    "Pour plus d'informations sur comment utiliser les GPU sur colab, vous pouvez lire ce [tutoriel](https://colab.research.google.com/drive/1y3ZE4m-D7lPoMzsypSEXessYmjWfKGqD#scrollTo=3IEVK-KFxi5Z).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxnZv9g_0RQK"
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "print(\"GPU Available: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2LZ9sxy8bs3"
   },
   "source": [
    "# Le perceptron multi-couche\n",
    "Un perceptron multi-couche est un réseau feed-forward simple. Il prend en entrée les images, les transforme à travers une série de couches cachées et finalement donne une sortie. Cette sortie correspond à la probabilité d'appartenance à l'une ou l'autre des classes de la cible.\n",
    "\n",
    "Par exemple, si on regarde un perceptron multi-couche qui classifie des images de chiffres du jeu de données MNIST :\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/mlp.png?raw=true)\n",
    "\n",
    "La procédure d'apprentissage typique pour ce modèle consiste en :\n",
    "<ul>\n",
    "<li>Définir l'architecture du réseau. Cela définira les paramètres (poids et biais) du réseau.</li>\n",
    "<li>Définir la fonction de coût et l'optimiseur.</li>\n",
    "<li>Entraîner le réseau.</li>\n",
    "<li>Tester le réseau.</li>\n",
    "</ul>\n",
    "\n",
    "Notez que cette procèdure est valable pour l'entraînement de tous type de réseau de neurones profonds.\n",
    "\n",
    "### Boîte à outils\n",
    "\n",
    "Rappelons qu'un réseau de neurones profond peut être construit en utilisant la librairie <a href=\"http://pytorch.org/docs/master/nn.html\">`torch.nn`</a>. `nn` travaille avec <a href=\"http://pytorch.org/docs/master/autograd.html\">`torch.autograd`</a> pour définir et différencier les modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUhdXQNdup2c"
   },
   "source": [
    "## Définir l'architecture du réseau\n",
    "### Boîte à outils\n",
    "\n",
    "Pour définir l'architecture du réseau en pytorch il faut créer une classe enfant de la classe parent <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Module\">`torch.nn.Module`</a> où les méthodes suivantes sont à compléter :\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne l'`output`.</li>\n",
    "</ul>\n",
    "\n",
    "Pour construire les couches de l'`__init__` du perceptron multi-couche, les classes suivantes peuvent être utilisées :\n",
    "<ul>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a> qui applique une transformation linéaire aux données d'entrée : y = Ax + b.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.ReLU\">`torch.nn.Relu()`</a> qui applique la fonction Relu éléments par éléments : Relu(x) = max(0, x).</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Softmax\">`torch.nn.Softmax(dim)`</a> qui applique la fonction Sofmax à un tenseur d'entrée à n-dimension en le normalisant de tel sorte que les éléments de tenseur de sortie à n-dimension soient dans l'intervalle [0, 1] et somment à 1.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Sequential\">`torch.nn.sequential`</a>  qui est un conteneur séquentiel dans lequel les modules sont ajoutés dans l'ordre dans lequel ils sont passés au constructeur.</li>\n",
    "</ul>\n",
    "\n",
    "Dans `forward(input)` on applique aux données d'entrée les différentes couches définies dans `__init__` les unes après les autres.\n",
    "\n",
    "Enfin, `model.to(device)` permet de passer le modèle sur GPU lorsque disponible.\n",
    "\n",
    "## Implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3xFquZ0xmUs"
   },
   "source": [
    "### Modèle\n",
    "\n",
    "Nous voulons implémenter un modèle à trois couches avec la non-linéarité ReLU entre chaque couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-3XHqgI8bs4"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, num_classes))\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        \n",
    "        out = self.hidden_layer(x)\n",
    "        \n",
    "        out = self.output_layer(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = MLP(input_size, hidden_size, num_classes)\n",
    "# switch model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "# Save the initial weights of model\n",
    "init_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFxIFvCSu7fj"
   },
   "source": [
    "\n",
    "### Nombre de paramètres\n",
    "\n",
    "En entrée, nous avons 28x28 pixels applatits, donc un vecteur de taille 1x784. Afin de passer à une seconde couche de taille 500, nous avons besoin de 500 vecteurs de poids 1x784, donc 784\\*500, ainsi que de 500 biais, donc 785\\*500 total. Continuant cette logique, nous avons un nombre total de paramètres de:\n",
    "\n",
    "`785*500 + 501*500 + 501*10 = 648010` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-t4PftT8bs7"
   },
   "source": [
    "## Définir la fonction de coût et l'optimiseur\n",
    "### Boîte à outils\n",
    "De nombreuses fonctions de coût et optimiseurs sont disponibles dans Pytorch. \n",
    "\n",
    "Rappelons qu'une fonction de coût $J(\\theta) = L(x, y, \\theta)$ prend en entrée le couple (prédiction, cible) et calcule une valeur qui estime la distance entre la prédiction et la cible. L'optimiseur dans le cas de la descente de gradient stochastique, ou Stochastic Gradient Descent (SGD), minimise la fonction de coût $J(\\theta)$ paramétrisée par les poids du modèle $\\theta \\in \\mathbb{R}^d$ en mettant à jour les poids itérativement suivant cette règle simple : `poids = poids - pas_d_apprentissage * gradient`.\n",
    "\n",
    "Un choix commun pour un problème de classification (notre cas) est d'utiliser les classes suivantes :\n",
    "<ul>\n",
    "<li>**Fonction de coût :** <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss\">`torch.nn.CrossEntropyLoss()`</a>. L'entropie croisée est souvent utilisée en optimisation. Elle permet de comparer une distribution $p$ avec une distibution de référence $t$. Elle est minimum lorsque $t=p$. Sa formule pour la calculer entre la prédiction et la cible est : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible. Note: la fonction <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss\">`torch.nn.CrossEntropyLoss()`</a> calcule par défaut la valeur softmax de la dernière couche. </li>\n",
    "<li>**Optimiseur :** <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a> qui est une implémentation de SGD.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rg7HNpSy8bs8"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1DUif-H8bs_"
   },
   "source": [
    "## Entraîner le réseau\n",
    "### Boîte à outils\n",
    "En général, l'entraînement d'un réseau se fait en itérant sur plusieurs époques (une époque correspond à une passe sur l'intégralité du jeu de données d'entraînement). Sur une époque on va recevoir une série de batches fournies par l'itérateur. Pour chaque batch, on fait les opérations suivantes:\n",
    "<ul>\n",
    "<li>`optimizer.zero_grad()` : on efface les gradients encore stockés par le réseau issus de la passe précédente.</li>\n",
    "<li>`loss.backward()` : on calcule automatiquement la dérivée du coût et on propage l'erreur dans le graphe par rétro-propagation.</li>\n",
    "<li>`optimizer.step()` : on effectue une étape de descente de gradient. Dans le cas de SGD, c'est une descente de gradient classique avec les gradients calculés précédemment : `poids = poids - pas_d_apprentissage * gradient`.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVh2Pbq98btA"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "model.load_state_dict(init_model_wts)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "print(\"# Start training #\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    \n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over train data\n",
    "    for images, labels in train_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Flatten the images\n",
    "        images = images.view(-1, 28*28)\n",
    "\n",
    "        # Zero the gradient buffer\n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_n_iter = 0\n",
    "    \n",
    "    # Set model to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate over valid data\n",
    "    for images, labels in valid_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Flatten the images\n",
    "        images = images.view(-1, 28*28)\n",
    "        \n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Statistics\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    train_loss_history.append(train_loss / train_n_iter)\n",
    "    valid_loss_history.append(valid_loss / valid_n_iter)\n",
    "    \n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('\\tTrain Loss: {:.4f}'.format(train_loss / train_n_iter))\n",
    "    print('\\tValid Loss: {:.4f}'.format(valid_loss / valid_n_iter))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AM0yhihy_rjR"
   },
   "source": [
    "Visualisons les courbes d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHUMeoJy_qNX"
   },
   "outputs": [],
   "source": [
    "# Save history for later\n",
    "mlp_train_loss_history = train_loss_history\n",
    "mlp_valid_loss_history = valid_loss_history\n",
    "\n",
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, mlp_train_loss_history, label='train')\n",
    "plt.plot(x, mlp_valid_loss_history, label='valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4cLnlFhW8btC"
   },
   "source": [
    "## Tester le réseau\n",
    "### Boîte à outils\n",
    "On évalue ensuite le réseau sur l'ensemble du jeu de données de test.\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX6_p5wx_tYv"
   },
   "outputs": [],
   "source": [
    "# Set model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over test data\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    # put images on proper device (GPU)\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Flatten the images\n",
    "    images = images.view(-1, 28*28)\n",
    "    \n",
    "\n",
    "    # Forward\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Statistics\n",
    "    total += labels.size(0)\n",
    "    correct += torch.sum(predicted == labels.data)\n",
    "\n",
    "print('Accuracy on the test set: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hp1YgKZb8btG"
   },
   "source": [
    "# Réseaux à convolutions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMbU21dg3Rqx"
   },
   "source": [
    "## Concepts\n",
    "\n",
    "Nous revisitons ici certains concepts de base pour les réseaux à convolutions.\n",
    "\n",
    "### Convolution\n",
    "\n",
    "Une convolution consiste à prendre un filtre *k* et le faire \"glisser\" le long de l'entrée *I* afin d'obtenir une sortie *I*\\**K*.\n",
    "\n",
    "Un exemple de convolution 2D:\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/numerical_no_padding_no_strides.gif?raw=true)\n",
    "\n",
    "\n",
    "### Filtres\n",
    "\n",
    "Les filtres (kernel) sont utilisés afin d'extraire l'information utile des inputs. Ils ont généralement une taille *n* \\* *n* avec *n* en général impair. La valeur des poids du filtre sont les paramètres qui seront appris par le réseau à convolution. \n",
    "\n",
    "Le filtre utilisé dans l'exemple de convolution précédent est:\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/d7acc4aeb74d9e9cb5fb51482a302196594837fe.png?raw=true)\n",
    "\n",
    "### Profondeur\n",
    "\n",
    "On utilise en général un nombre *M* de filtres qui correspondra à la profondeur de la couche. La profondeur en soit est un hyperparamètre du réseau. Ici, chaque filtre (cercles bleu), contribue à une couche de profondeur de l'image en sortie.\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/Conv_layer.png?raw=true)\n",
    "\n",
    "### Pas\n",
    "\n",
    "Le pas, ou *stride*, correspond à la taille du pas (mesuré en pixels) effectué lors de l'opération de la convolution. On emploie généralement un pas de 1 ou 2. Plus le pas est élevé, plus la dimension en sortie sera réduite.\n",
    "\n",
    "### Marge à zéro\n",
    "\n",
    "La marge à zéro, ou *zero padding*, consiste à ajouter une bordure de zéros autour du input. Ceci peut être utile, par exemple, lorsqu'on souhaite préserver la dimension de l'entrée à la sortie.\n",
    "\n",
    "Voici un exemple de marge à zéro qui préserve la taille de l'entrée à la sortie. Ici, la marge à zéro=1, pas=1, et le filtre est de taille 3x3.\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/same_padding_no_strides.gif?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "### Max Pooling\n",
    "\n",
    "Il est commun de retrouver dans les réseaux à convolutions des couches de *pooling*. Le but du pooling est de réduire la dimension des inputs entres couches de convolutions afin de réduire le nombre de paramètres nécessaires du réseau. Dans le cas de LeNet, nous nous servons d'un max pooling avec taille de filtre 2x2 et pas de 2. Ceci consiste à prendre la valeur maximale d'une région 2x2 puis de s'en servir comme input à la prochaine couche.\n",
    "\n",
    "Voici un exemple de max pooling:\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/maxpool.jpeg?raw=true)\n",
    "\n",
    "\n",
    "### Champ de vision\n",
    "\n",
    "Le champ de vision, ou *Receptive Field*, est une mesure de la capacité du réseau à percevoir les détails à différentes échelles du input.  Dans un MLP, toutes les entrées sont connectés (fully connected), donc le champ de vision est la totalité de l'image. Dans le cas d'un réseau à convolution, plus il y a de filtres successifs, plus nous ajoutons au champ de vision. Considérons le cas simple d'un filtre 3x3 avec stride=1. Dans ce cas, pour un réseau à une couche, notre champ de vision est au maximum de 3x3. Cependant, plus nous ajoutons de couches, plus nous augmentons notre champ de vision. En ajoutant une seconde couche 3x3 avec pas de 1, notre champ de vision augmente a 5x5. En ajoutant une 3ème couche 3x3, notre champ de vision effectif est de 7x7. En utilisant 3 filtres 3x3 successifs, notre réseau necessite 3x3x3=27 paramètres, tandis qu'en utilisant 1 seul filtre de taille 7x7 requiert 49 paramètres. Il est donc plus optimal d'utliser plusieurs filtres successifs qu'un seul gros filtre pour un champ de vision équivalent. Également, en utilisant plusieurs filtres successifs, nous pouvons introduire plusieurs non-linéarités dans notre modèle.\n",
    "\n",
    "Ici, le filtre de taille 3x3 (bordures grises) avec pas de 1 a un champ de vision de 5x5 (région jaune)\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/sNBmKMKAz-yJeCuS14usSqw.png?raw=true)\n",
    "\n",
    "\n",
    "### Calculs de dimensions\n",
    "\n",
    "De façon générale, pour une couche de convolution avec entrée de dimenion du volume\n",
    "$W_1 * H_1 * D_1$ et avec les hyperparamètres\n",
    "\n",
    "* Nombre de filtres = $K$\n",
    "\n",
    "* Taille de filtre = $F$\n",
    "\n",
    "* Taille de pas $S$\n",
    "\n",
    "* Taille de marge $P$\n",
    "\n",
    "Nous obtenons un volume en sortie de $W_2 * H_2 * D_2$ où \n",
    "\n",
    "* $W_2 = (W_1 - F + 2P) / S + 1$\n",
    "* $H_2 = (H1 - F + 2P) / S + 1$\n",
    "* $D_2 = K$\n",
    "\n",
    "avec un nombre de paramètres total de $(F⋅F⋅D_1)⋅K$ poids et $K$ biais.\n",
    "\n",
    "Pour une analyse plus détaillée, consultez [cet article](http://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owIcd9VguyAe"
   },
   "source": [
    "\n",
    "## LeNet\n",
    "LeNet est un réseau à convolution simple pour la classification. Il en existe plusieurs versions. Il est préférable d'utiliser un réseau à convolution pour de la classification d'images car ce type de réseau prend en compte la structure de l'image et à taille de réseau équivalent a un nombre de paramètres plus faible.\n",
    "\n",
    "Par exemple, si on prend l'exemple de LeNet 5 pour classifier les images de chiffres du jeu de données MNIST :\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/lenet5.png?raw=true)\n",
    "\n",
    "\n",
    "La procédure d'apprentissage typique pour ce modèle est la même que pour le perceptron multi-couche et consiste en :\n",
    "<ul>\n",
    "<li>Définir l'architecture du réseau. Cela définira les paramètres (poids et biais) du réseau.</li>\n",
    "<li>Définir la fonction de coût et l'optimiseur.</li>\n",
    "<li>Entraîner le réseau.</li>\n",
    "<li>Tester le réseau.</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "## Définir l'architecture du réseau\n",
    "### Boîte à outils\n",
    "**Rappel :** Pour définir l'architecture du réseau en pytorch il faut créer une classe enfant de la classe parent <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Module\">`torch.nn.Module`</a> où les méthodes suivantes sont à compléter :\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne l'`output`.</li>\n",
    "</ul>\n",
    "\n",
    "Pour construire les couches de l'`__init__` de LeNet 5, les classes suivantes peuvent être utilisées :\n",
    "<ul>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Conv2d\">`torch.nn.Conv2d(in_channels, out_channels, kernel_size)`</a> qui applique une convolution 2D sur un signal d'entrée composé de plusieurs canaux d'entrée.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.MaxPool2d\">`torch.nn.MaxPool2d(kernel_size)`</a> qui applique du max pooling 2D sur un signal d'entrée composé de plusieurs canaux d'entrée.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a> qui applique une transformation linéaire aux données d'entrée : y = Ax + b.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.ReLU\">`torch.nn.Relu()`</a> qui applique la fonction Relu éléments par éléments : Relu(x) = max(0, x).</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Softmax\">`torch.nn.Softmax(dim)`</a> qui applique la fonction Sofmax à un tenseur d'entrée à n-dimension en le normalisant de tel sorte que les éléments de tenseur de sortie à n-dimension soient dans l'intervalle [0, 1] et somment à 1.</li>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Sequential\">`torch.nn.sequential`</a>  qui est un conteneur séquentiel dans lequel les modules sont ajoutés dans l'ordre dans lequel ils sont passés au constructeur.</li>\n",
    "</ul>\n",
    "\n",
    "Dans `forward(input)` on applique aux données d'entrée les différentes couches définies dans `__init__` les unes après les autres.\n",
    "Il est aussi nécessaire de changer la forme des données juste avant l'appel à la couche linéaire, celle-ci n'acceptant que des données uni-dimensionelles. Il est possible d'utiliser <a href=\"https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view\">`torch.Tensor.view(new_shape)`</a> pour cela.\n",
    "\n",
    "Enfin, `model.to(\"cuda:0\")` permet de passer le modèle sur GPU.\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sR4OQa-4gBAQ"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # À compléter\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # À compléter\n",
    "        \n",
    "        return out\n",
    "        \n",
    "model = LeNet5()\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRo03AR2PFPE"
   },
   "source": [
    " Ici, on observe 28 938 paramètres pour LeNet5 contre 648 010 paramètres pour le MLP à deux couches cachées. On a donc une réduction significative du nombre de paramètres entre LeNet5 et le MLP précédent. Le calcul du nombre de paramètres se résume ainsi:\n",
    " \n",
    "\n",
    "\n",
    "```\n",
    "1ère couche: 16 filtres de taille 5x5 + 16 biais = 16*5*5 + 16 = 416\n",
    "2ème couche: 16 * 32 filtres de taille 5x5 + 32 biais = 16*32*5*5 + 32 = 12 832\n",
    "Couche FC: 7*7*32*10 + 10 biais = 15 690\n",
    " \n",
    "Total = 416 + 12 832 + 15 690 = 28 938\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuPJFPoDQYLq"
   },
   "outputs": [],
   "source": [
    "# Save the initial weights of model\n",
    "init_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9H0ssbh3V1j"
   },
   "source": [
    "## Définir la fonction de coût et l'optimiseur\n",
    "### Boîte à outils\n",
    "**Rappel : ** un choix commun pour un problème de classification (notre cas) est d'utiliser les classes suivantes :\n",
    "<ul>\n",
    "<li>**Fonction de coût :** <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss\">`torch.nn.CrossEntropyLoss()`</a>. L'entropie croisée est souvent utilisée en optimisation. Elle permet de comparer une distribution $p$ avec une distibution de référence $t$. Elle est minimum lorsque $t=p$. Sa formule pour la calculer entre la prédiction et la cible est : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible.</li>\n",
    "<li>**Optimiseur :** <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a> qui est une implémentation de SGD.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uE3Cfrd-hJ0e"
   },
   "outputs": [],
   "source": [
    "# À compléter\n",
    "\n",
    "criterion = ...\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYEtUb4s3rab"
   },
   "source": [
    "## Entraîner le réseau\n",
    "### Boîte à outils\n",
    "**Rappel :** en général, l'entraînement d'un réseau se fait en itérant sur plusieurs époques (une époque correspond à une passe sur l'intégralité du jeu de données d'entraînement). Sur une époque on va recevoir une série de batches fournies par l'itérateur. Pour chaque batch, on fait les opérations suivantes:\n",
    "<ul>\n",
    "<li>`optimizer.zero_grad()` : on efface les gradients encore stockés par le réseau issus de la passe précédente.</li>\n",
    "<li>`loss.backward()` : on calcule automatiquement la dérivée du coût et on propage l'erreur dans le graphe par rétro-propagation.</li>\n",
    "<li>`optimizer.step()` : on effectue une étape de descente de gradient. Dans le cas de SGD, c'est une descente de gradient classique avec les gradients calculés précédemment : `poids = poids - pas_d_apprentissage * gradient`.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation\n",
    "C'est simple, compléter les trous...\n",
    "\n",
    "Bonne chance !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elxupovwhRSk"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(init_model_wts)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "print(\"# Start training #\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    \n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over train data\n",
    "    for images, labels in train_loader:  \n",
    "\n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Zero the gradient buffer\n",
    "        ...\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(...)\n",
    "        \n",
    "        # Backward pass\n",
    "        ...\n",
    "        \n",
    "        # Optimize\n",
    "        ...\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_n_iter = 0\n",
    "    \n",
    "    # Set model to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate over valid data\n",
    "    for images, labels in valid_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(...)\n",
    "        \n",
    "        # Statistics\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    train_loss_history.append(train_loss / train_n_iter)\n",
    "    valid_loss_history.append(valid_loss / valid_n_iter)\n",
    "    \n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('\\tTrain Loss: {:.4f}'.format(train_loss / train_n_iter))\n",
    "    print('\\tValid Loss: {:.4f}'.format(valid_loss / valid_n_iter))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3fozzXmdRGTs"
   },
   "source": [
    "Visualisons les courbes d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUGbFeg5RHFZ"
   },
   "outputs": [],
   "source": [
    "# Save history for later\n",
    "lenet5_train_loss_history = train_loss_history\n",
    "lenet5_valid_loss_history = valid_loss_history\n",
    "\n",
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, lenet5_train_loss_history, label='train')\n",
    "plt.plot(x, lenet5_valid_loss_history, label='valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H6kWtULrSDXL"
   },
   "source": [
    "On peut superposer les courbes d'entraînement et de validation de LeNet5 et du MLP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rE1qsmvaSTjH"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, mlp_train_loss_history, label='MLP train')\n",
    "plt.plot(x, mlp_valid_loss_history, label='MLP valid')\n",
    "plt.plot(x, lenet5_train_loss_history, label='LeNet5 train')\n",
    "plt.plot(x, lenet5_valid_loss_history, label='LeNet5 valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tq79RTld3xyc"
   },
   "source": [
    "## Tester le réseau\n",
    "### Boîte à outils\n",
    "**Rappel :** on évalue ensuite le réseau sur l'ensemble du jeu de données de test.\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "da47-MilhpN7"
   },
   "outputs": [],
   "source": [
    "# Set model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over data.\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    # put images on proper device (GPU)\n",
    "    images = ...\n",
    "    labels = ...\n",
    "    \n",
    "    # No need to flatten the images here !\n",
    "    \n",
    "\n",
    "    # Forward\n",
    "    outputs = ...\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Statistics\n",
    "    total += labels.size(0)\n",
    "    correct += ...\n",
    "\n",
    "print('Accuracy on the test set: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voN-_iO_RQ8A"
   },
   "source": [
    "On obtient de meilleurs résultats après 10 époques !\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFj_W39u5voa"
   },
   "source": [
    "## Méthodes pratiques pour améliorer l'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chov57bzu76J"
   },
   "source": [
    "### Batch normalization\n",
    "Le *batch normalization* est une astuce qui permet, en pratique, au modèle d'apprendre plus vite. Elle agit comme régularisateur en normalisant les entrées par batch, de manière différentiable. Les données en sorties de cette couche auront une moyenne proche de 0 et une variance proche de 1.\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/1_Hiq-rLFGDpESpr8QNsJ1jg.png?raw=true)\n",
    "\n",
    "\n",
    "Pour plus d'informations sur le *Batch Normalization*, consultez cet [article](https://arxiv.org/pdf/1502.03167v3.pdf).\n",
    "\n",
    "### Boîte à outils\n",
    "Pour ajouter la batch normalisation dans LeNet5, il suffit de l'ajouter parmis les couches de l'`__init__` et de l'appeler après chaque couche de convolution. La classe suivante peut être utilisée:\n",
    "<ul>\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.BatchNorm2d\">`nn.BatchNorm2d(num_features)`</a> : permet d'ajouter de la batch normalisation à une entrée à 4 dimensions présentée sous la forme d'un tenseur à 3 dimensions.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pi_mhvg8E4E"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # À compléter\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # À compléter\n",
    "        \n",
    "        return out\n",
    "        \n",
    "model = LeNet5()\n",
    "model = model.to(device)\n",
    "  \n",
    "print(model)\n",
    "\n",
    "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "271HrQBNccH1"
   },
   "source": [
    "Ici, on observe 29 034 paramètres pour LeNet5 avec batch normalisation contre 28 938 paramètres pour LeNet5 sans batch normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vnbesUOudO_s"
   },
   "outputs": [],
   "source": [
    "# Save the initial weights of model\n",
    "init_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rj4R3qV5ABFC"
   },
   "source": [
    "**L'implémentation de la fonction de coût, l'optimiseur, les boucles d'entraînement et de test du réseau reste inchangé !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgEcoSRQAVtA"
   },
   "outputs": [],
   "source": [
    "criterion = ...\n",
    "optimizer = ...\n",
    "model.load_state_dict(init_model_wts)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "num_epochs = 10\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "print(\"# Start training #\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    \n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Iterate over train data\n",
    "    for images, labels in train_loader:  \n",
    "\n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Zero the gradient buffer\n",
    "        ...\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(...)\n",
    "        \n",
    "        # Backward pass\n",
    "        ...\n",
    "        \n",
    "        # Optimize\n",
    "        ...\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_n_iter = 0\n",
    "    \n",
    "    # Set model to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate over valid data\n",
    "    for images, labels in valid_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(...)\n",
    "        \n",
    "        # Statistics\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    train_loss_history.append(train_loss / train_n_iter)\n",
    "    valid_loss_history.append(valid_loss / valid_n_iter)\n",
    "    \n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('\\tTrain Loss: {:.4f}'.format(train_loss / train_n_iter))\n",
    "    print('\\tValid Loss: {:.4f}'.format(valid_loss / valid_n_iter))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6pxvS_yUeWog"
   },
   "source": [
    "On obtient d'encore meilleurs résultats après 10 époques !\n",
    "\n",
    "Regardons les coubres d'entraînement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrv-o7Cle0ty"
   },
   "outputs": [],
   "source": [
    "# Save history for later\n",
    "lenet5_batchnorm_train_loss_history = train_loss_history\n",
    "lenet5_batchnorm_valid_loss_history = valid_loss_history\n",
    "\n",
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, lenet5_train_loss_history, label='LeNet5 train')\n",
    "plt.plot(x, lenet5_valid_loss_history, label='LeNet5 valid')\n",
    "plt.plot(x, lenet5_batchnorm_train_loss_history, label='LeNet5 batch norm train')\n",
    "plt.plot(x, lenet5_batchnorm_valid_loss_history, label='LeNet5 batch norm valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CHqHLCP6Crmp"
   },
   "source": [
    "# Transfer Learning : finetuning d'un réseau à convolution\n",
    "**Attribution :** cette partie reprend en partie le tutoriel : http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "En pratique, il est peu commun d'entraîner un réseau à convolution à partir de rien (c'est-à-dire avec une initialisation des poids aléatoires). En effet, souvent, le jeu de données d'intérêt est trop petit. A la place, il est commun de pré-entraîner le réseau sur un jeu de données plus gros comme, par exemple, un sous-ensemble d'ImageNet (1.2 millions d'images avec 1000 catégories). Ce réseau pré-entraîné est ensuite utilisé comme initialisation des poids du réseau qui sera entraîné sur le jeu de données d'intérêt. On parle de finetuning du réseau à convolution. A noter que le réseau pré-entraîné peut aussi être utilisé pour extraire de nouvelles variables du jeu de données d'intérêt. On parle de transfer learning.\n",
    "\n",
    "Nous allons maintenant étudier plus en détail le scénario du finetuning pour le transfer learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "itOkLFisvKqI"
   },
   "source": [
    "## Télécharger les données et créer le chargeur de données\n",
    "Le jeu de données que nous allons étudier est un sous-ensemble d'ImageNet qui contient environ $120 \\times 2$ images d'entraînement et $75 \\times 2$ images de test de fourmis et d'abeilles. Le but est de classifier ces deux classes. Ci-dessous, un exemples d'images de ce jeu de données :\n",
    "\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/fourmi_abeille.png?raw=true)\n",
    "\n",
    "### Boîte à outils\n",
    "**Rappel :** une façon simple de charger les données dans PyTorch est : \n",
    "<ul>\n",
    "<li>D'utiliser une classe enfant de la classe parent <a href=\"http://pytorch.org/docs/master/data.html#torch.utils.data.Dataset\">`torch.utils.data.Dataset`</a> où les méthodes `__getitem__` et `__len__` sont à compléter. Notez qu' à ce stade, les données ne sont pas chargées en mémoire.</li>\n",
    "<li>D'utiliser la classe <a href=\"http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader\">`torch.utils.data.DataLoader`</a> pour lire et mettre en mémoire les données.</li>\n",
    "</ul>\n",
    "\n",
    "**Remarque :** <a href=\"http://pytorch.org/docs/master/torchvision/datasets.html#torchvision-datasets\">`torchvision.datasets`</a> peut aussi être utilisé pour charger des données à partir d'un dossier.\n",
    "\n",
    "**Augmentation des données :** pour augmenter les données, <a href=\"http://pytorch.org/docs/master/torchvision/transforms.html#torchvision-transforms\">`torchvision.transforms`</a> fournit les transformations d'images courantes. Ces transformations peuvent être appliquées successivement en utilisant la classe <a href=\"http://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.Compose\">`torchvision.transforms.Compose`</a>.\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LW-1CauxEQM"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "## DOWNLOAD DATASET ##\n",
    "if [ ! -d \"hymenoptera_data\" ]; then\n",
    "  wget --quiet https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
    "  unzip -q hymenoptera_data.zip\n",
    "  rm hymenoptera_data.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMvya9Oxps5z"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "def make_dataset(root, split_type):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    root_dir : string\n",
    "    Directory with all the images.\n",
    "    split_type : string\n",
    "    The name of the split in {'train', 'valid'}.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    images : dict\n",
    "    Dict of images path for each classes for a specific split type.\n",
    "    \"\"\"\n",
    "\n",
    "    images = {}\n",
    "    root = os.path.join(root, split_type)\n",
    "\n",
    "    for classes in sorted(os.listdir(root)):\n",
    "        images[classes] = []\n",
    "    path_classes = os.path.join(root, classes)\n",
    "\n",
    "    for root_, _, fnames in sorted(os.walk(path_classes)):\n",
    "        for fname in sorted(fnames):\n",
    "            if fname.endswith('.jpg'):\n",
    "                item = os.path.join(root_, fname)\n",
    "                images[classes].append(item)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "class HymenopteraDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Hymenoptera dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, split_type='train', transform=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        root_dir : string\n",
    "           Directory with all the images.\n",
    "        split_type : string\n",
    "           The name of the split in {'train', 'valid', 'test', 'train_valid'}.\n",
    "        transform : callable, optional\n",
    "           Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split_type = split_type\n",
    "        self.transform = transform\n",
    "        self.classes = {'ants': 0, 'bees': 1}\n",
    "\n",
    "        imgs_ = []\n",
    "        target_ = []\n",
    "\n",
    "        if split_type == 'train':\n",
    "            imgs = make_dataset(root_dir, 'train')\n",
    "            for k, v in imgs.items():\n",
    "                imgs_ += imgs[k][:int(0.8*len(v))]\n",
    "                target_ += [self.classes[k]] * len(imgs_)\n",
    "\n",
    "        elif split_type == 'valid':\n",
    "            imgs = make_dataset(root_dir, 'train')\n",
    "            for k, v in imgs.items():\n",
    "                imgs_ += imgs[k][int(0.8*len(v)):]\n",
    "                target_ += [self.classes[k]] * len(imgs_)\n",
    "\n",
    "        elif split_type == 'train_valid':\n",
    "            imgs = make_dataset(root_dir, 'train')\n",
    "            for k, v in imgs.items():\n",
    "                imgs_ += imgs[k]\n",
    "                target_ += [self.classes[k]] * len(imgs_)\n",
    "\n",
    "        elif split_type == 'test':\n",
    "            imgs = make_dataset(root_dir, 'val')\n",
    "            for k, v in imgs.items():\n",
    "                imgs_ += imgs[k]\n",
    "                target_ += [self.classes[k]] * len(imgs_)\n",
    "\n",
    "        self.imgs = imgs_\n",
    "        self.target = np.array(target_)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of image in the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "           The number of images in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get the items : image, target\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        index : int\n",
    "           Index\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        img : tensor\n",
    "           The image.\n",
    "        target : int\n",
    "           Target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path = self.imgs[index]\n",
    "        target = self.target[index]\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                img.convert('RGB')\n",
    "\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9BHo5WsOghr"
   },
   "source": [
    "## Augmentation des données \n",
    "Une astuce souvent utilisée pour éviter l'overfit et augmenter la taille apparente du jeu de données d'entrainement est l'augmentation de données. Il s'agit de différents types de transformations aux inputs afin de les déformer légèrement les images. Par exemple, les images peuvent être agrandies, élargies, tournées sur elle mêmes, miroitées, etc. Voici un exemple de différentes augmentations:\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/1_Jujct_Pt-zvdWtSFpHUp3Q.png?raw=true)\n",
    "\n",
    "\n",
    "Pour augmenter les données, <a href=\"http://pytorch.org/docs/master/torchvision/transforms.html#torchvision-transforms\">`torchvision.transforms`</a> fournit les transformations d'images courantes. Ces transformations peuvent être appliquées successivement en utilisant la classe <a href=\"http://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.Compose\">`torchvision.transforms.Compose`</a>.\n",
    "\n",
    "Ajoutez les transformations suivantes pour l'ensemble d'entraînement:\n",
    "* Un crop aléatoire qui redimensionne l'image à une taille 224x224\n",
    "* Une probabilité aléatoire de prendre une copie miroitée de l'image\n",
    "* Une normalisation avec les valeurs suivantes pour les moyennes et écarts types: [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "Pour l'ensemble de validation, redimensionnez l'image à 256x256, prenez un crop à partir du centre de l'image et normalisez l'image avec les mêmes valeurs que pour l'ensemble d'entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v94wZLuOp4m3"
   },
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        # À compléter    \n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        # À compléter\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8i9eB9I_p5sJ"
   },
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "data_dir = 'hymenoptera_data'\n",
    "\n",
    "data_train = HymenopteraDataset(data_dir, 'train', data_transforms['train'])\n",
    "train_loader = DataLoader(data_train, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "data_valid = HymenopteraDataset(data_dir, 'valid', data_transforms['valid'])\n",
    "valid_loader = DataLoader(data_valid, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "data_test = HymenopteraDataset(data_dir, 'test', data_transforms['valid'])\n",
    "test_loader = DataLoader(data_test, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "print('# images in data train: {}'.format(len(data_train)))\n",
    "print('# images in data valid: {}'.format(len(data_valid)))\n",
    "print('# images in data test: {}'.format(len(data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pl1X1vt5AVaf"
   },
   "source": [
    "Visualisons les données d'entraînement !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4kbOO5XAUO5"
   },
   "outputs": [],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "print('Classes: {}'.format(data_train.classes))\n",
    "print('Inputs size: {}'.format(inputs.size()))\n",
    "print('Classes size: {}'.format(classes.size()))\n",
    "\n",
    "# Random image of the batch\n",
    "idx = np.random.randint(len(inputs))\n",
    "img = inputs[idx]\n",
    "labels = list(data_train.classes.keys())\n",
    "img_label = labels[(classes[idx])]\n",
    "\n",
    "img = img.numpy().transpose((1, 2, 0))\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "img = std * img + mean\n",
    "img = np.clip(img, 0, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(img_label)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qh3bKAO7Lf14"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "def imshow(img, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "inputs, classes = next(iter(train_loader))\n",
    "\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "class_names = data_train.classes\n",
    "class_names = {class_names[k]: k for k in class_names.keys()}\n",
    "\n",
    "imshow(out, title=[class_names[int(x)] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN9JbYASp4tE"
   },
   "source": [
    "## Définir l'architecture du réseau\n",
    "### Boîte à outils\n",
    "Ici, nous voulons réutiliser un réseau pré-entrainé sur ImageNet. Pour cela, il faut charger un modèle pré-entraîné et réinitialiser la couche finale qui est la couche complètement connectée. Par chance, dans Pytorch, <a href=\"http://pytorch.org/docs/0.1.12/torchvision/models.html#module-torchvision.models\">`torchvision.models`</a> propose des architectures toutes faites où les poids ont déjà été entraînés sur ImageNet.\n",
    "\n",
    "Un choix commun pour un problème de classification (notre cas) est d'utiliser le modèle *ResNet18*. Pour plus d'informations sur cette architecture, consultez cet [article](https://arxiv.org/abs/1512.03385). Vous pouvez également consulter la documentation PyTorch du modèle:\n",
    "<a href=\"http://pytorch.org/docs/0.1.12/torchvision/models.html#torchvision.models.resnet18\">`torchvision.models.resnet18(pretrained=True)`</a>\n",
    "\n",
    "Un exemple de bloc résiduel est donné ci-dessous :\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/bloc_residuel.png?raw=true)\n",
    "\n",
    "\n",
    "**Rappel :** <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a> permet d'appliquer une transformation linéaire à des données d'entrée : y = Ax + b.\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TiQfdQxiMJPQ"
   },
   "source": [
    "Dans un premier temps on va utiliser un modèle non pré-entraîné puis on utilisera le même modèle mais cette fois-ci pré-entraîné afin de comparer les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxBgVe4NISea"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load non-pre-trained resnet18 model\n",
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "# Reset last layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQTyN1tkZyYG"
   },
   "outputs": [],
   "source": [
    "# Save the initial weights of model\n",
    "init_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_ut6uP0qpWW"
   },
   "source": [
    "## Définir la fonction de coût et l'optimiseur\n",
    "### Boîte à outils\n",
    "**Rappel : ** un choix commun pour un problème de classification (notre cas) est d'utiliser les classes suivantes :\n",
    "<ul>\n",
    "<li>**Fonction de coût :** <a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss\">`torch.nn.CrossEntropyLoss()`</a>. L'entropie croisée est souvent utilisée en optimisation. Elle permet de comparer une distribution $p$ avec une distibution de référence $t$. Elle est minimum lorsque $t=p$. Sa formule pour la calculer entre la prédiction et la cible est : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible.</li>\n",
    "<li>**Optimiseur :** <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a>. Utilisez un taux d'apprentissage de 1e-3 et une valeur de momentum de 0.9</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JW00K1Ssqqcm"
   },
   "outputs": [],
   "source": [
    "criterion = ...\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9uhoTb410Utx"
   },
   "source": [
    "## Entraîner le réseau\n",
    "### Boîte à outils\n",
    "**Rappel :** en général, l'entraînement d'un réseau se fait en itérant sur plusieurs époques (une époque correspond à une passe sur l'intégralité du jeu de données d'entraînement). Sur une époque on va recevoir une série de batches fournies par l'itérateur. Pour chaque batch, on fait les opérations suivantes:\n",
    "<ul>\n",
    "<li>`optimizer.zero_grad()` : on efface les gradients encore stockés par le réseau issus de la passe précédente.</li>\n",
    "<li>`loss.backward()` : on calcule automatiquement la dérivée du coût et on propage l'erreur dans le graphe par rétro-propagation.</li>\n",
    "<li>`optimizer.step()` : on effectue une étape de descente de gradient. Dans le cas de SGD, c'est une descente de gradient classique avec les gradients calculés précédemment : `poids = poids - pas_d_apprentissage * gradient`. Dans le cas d'Adam une opération légérement plus complexe est réalisée.</li>\n",
    "</ul>\n",
    "\n",
    "**Conseils bonus :** L'orsque l'on entraîne le réseau de neurones profonds, il est conseillé de faire :\n",
    "<ul>\n",
    "<li>de l'early stopping. C'est une forme de régularisation qui évite de faire du sur-apprentissage en utilisant une règle pour stopper l'apprentissage du modèle.</li>\n",
    "<li>du checkpointing. Pour cela, il est commun d'enregister les poids du réseau accessible avec `model.state_dict()` à différentes étapes de l'entraînement.</li>\n",
    "<li>d'imprimer les temps d'exécution. Pour cela, il est commun d'utilier `time.time()`.</li>\n",
    "</ul>\n",
    "\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXNpyIj_wxRP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "print(\"# Start training #\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    \n",
    "    # Set model to train mode\n",
    "    ...\n",
    "    \n",
    "    # Iterate over train data\n",
    "    for images, labels in train_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "\n",
    "        # Zero the gradient buffer\n",
    "        ...\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = ...\n",
    "        \n",
    "        loss = criterion(...)\n",
    "        \n",
    "        # Backward Pass\n",
    "        ...\n",
    "        \n",
    "        # Optimize\n",
    "        ...\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_n_iter = 0\n",
    "    \n",
    "    # Set model to evaluate mode\n",
    "    ...\n",
    "    \n",
    "    # Iterate over valid data\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in valid_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Forward\n",
    "        outputs = ...\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # Statistics\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(predicted == labels.data)\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    # Deep copy the best model\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    train_loss_history.append(train_loss / train_n_iter)\n",
    "    valid_loss_history.append(valid_loss / valid_n_iter)\n",
    "    \n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('\\tTrain Loss: {:.4f}'.format(train_loss / train_n_iter))\n",
    "    print('\\tValid Loss: {:.4f}'.format(valid_loss / valid_n_iter))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "print('\\n\\nBest valid accuracy: {:.2f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr8-PgSmiQSF"
   },
   "source": [
    "Visualisons les courbes d'entraînement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njb7oaT-hfk3"
   },
   "outputs": [],
   "source": [
    "resnet18_train_loss_history = train_loss_history\n",
    "resnet18_valid_loss_history = valid_loss_history\n",
    "\n",
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, resnet18_train_loss_history, label='ResNet18 train')\n",
    "plt.plot(x, resnet18_valid_loss_history, label='ResNet18 valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vcqa0H5p-FHq"
   },
   "source": [
    "## Tester le réseau\n",
    "### Boîte à outils\n",
    "**Rappel :** on évalue ensuite le réseau sur l'ensemble du jeu de données de test.\n",
    "\n",
    "**Remarque :** ici, nous n'avons pas de données de test donc nous testons sur l'ensemble de validation (à ne pas faire en pratique).\n",
    "\n",
    "**Utilisation des poids du meilleur modèle :** comme nous avons fait de l'early stopping lors de l'entraînement, nous voulons réutiliser les poids du meilleur modèle sur l'ensemble de validation pour tester le modèle. Ces poids ont été enregistrés lors de l'entraînement du modèle dans `best_model_wts`. Pour les charger il suffit d'utiliser `model.load_state_dict(best_model_wts)`.\n",
    "### Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1DCCblW_EPo"
   },
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Set model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over test data\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    # put images on proper device (GPU)\n",
    "    images = ...\n",
    "    labels = ...\n",
    "    \n",
    "    # Forward\n",
    "    outputs = ...\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Statistics\n",
    "    total += labels.size(0)\n",
    "    correct += torch.sum(predicted == labels.data)\n",
    "\n",
    "print('Accuracy on the test set: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d38Q32VMN0Hb"
   },
   "source": [
    "Avec les poids pré-entraînés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMbvwaR5Ny-K"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Load pre-trained resnet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Reset last layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAcPL09nN-Ki"
   },
   "outputs": [],
   "source": [
    "# Save the initial weights of model\n",
    "init_model_wts = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88Nhc4mlN-sc"
   },
   "outputs": [],
   "source": [
    "criterion = ...\n",
    "optimizer = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1pQBFbAOEjd"
   },
   "outputs": [],
   "source": [
    "since = time.time()\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "num_epochs = 25\n",
    "best_acc = 0.0\n",
    "\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "print(\"# Start training #\")\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    \n",
    "    # Set model to train mode\n",
    "    ...\n",
    "    \n",
    "    # Iterate over train data\n",
    "    for images, labels in train_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "\n",
    "        # Zero the gradient buffer\n",
    "        ...\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = ...\n",
    "        \n",
    "        loss = ...\n",
    "        \n",
    "        # Backward pass\n",
    "        ...\n",
    "        \n",
    "        # Optimize\n",
    "        ...\n",
    "        \n",
    "        # Statistics\n",
    "        train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "    \n",
    "    valid_loss = 0\n",
    "    valid_n_iter = 0\n",
    "    \n",
    "    # Set model to evaluate mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Iterate over valid data\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for images, labels in valid_loader:  \n",
    "        \n",
    "        # put images on proper device (GPU)\n",
    "        images = ...\n",
    "        labels = ...\n",
    "        \n",
    "        # Forward\n",
    "        outputs = ...\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "    \n",
    "        # Statistics\n",
    "        total += labels.size(0)\n",
    "        correct += torch.sum(predicted == labels.data)\n",
    "        valid_loss += loss.item()\n",
    "        valid_n_iter += 1\n",
    "    \n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    # Deep copy the best model\n",
    "    if epoch_acc > best_acc:\n",
    "        best_acc = epoch_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    train_loss_history.append(train_loss / train_n_iter)\n",
    "    valid_loss_history.append(valid_loss / valid_n_iter)\n",
    "    \n",
    "    print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "    print('\\tTrain Loss: {:.4f}'.format(train_loss / train_n_iter))\n",
    "    print('\\tValid Loss: {:.4f}'.format(valid_loss / valid_n_iter))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "print('\\n\\nTraining complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "print('\\n\\nBest valid accuracy: {:.2f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_x_Kot7iEnI"
   },
   "source": [
    "Visualisons les courbes d'entraînement et de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVUPxQCehyzc"
   },
   "outputs": [],
   "source": [
    "resnet18_pretrained_train_loss_history = train_loss_history\n",
    "resnet18_pretrained_valid_loss_history = valid_loss_history\n",
    "\n",
    "# Plot training and validation curve\n",
    "x = range(1, num_epochs + 1)\n",
    "plt.plot(x, resnet18_train_loss_history, label='ResNet18 train')\n",
    "plt.plot(x, resnet18_valid_loss_history, label='ResNet18 valid')\n",
    "plt.plot(\n",
    "      x, resnet18_pretrained_train_loss_history,\n",
    "    label='ResNet18 pretrained train')\n",
    "plt.plot(\n",
    "      x, resnet18_pretrained_valid_loss_history,\n",
    "    label='ResNet18 pretrained valid')\n",
    "\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "keq8hL3yiCOG"
   },
   "source": [
    "Testons le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJy4FdfQfc7z"
   },
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Set model to evaluate mode\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over test data\n",
    "for images, labels in test_loader:\n",
    "    \n",
    "    # put images on proper device (GPU)\n",
    "    images = ...\n",
    "    labels = ...\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = ...\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Statistics\n",
    "    total += labels.size(0)\n",
    "    correct += torch.sum(predicted == labels.data)\n",
    "\n",
    "print('Accuracy on the test set: {:.2f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LMd3mx5KKYXk"
   },
   "source": [
    "On observe une augmentation de l'accuracy sur le test par rapport au modèle dont les poids n'avaient pas été entraîné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u69CX2svt_4l"
   },
   "source": [
    "# Suite (optionnelle)\n",
    "\n",
    "Si vous souhaitez approfondir vos connaissances sur les réseaux à convolution, voici une série de liens vers divers méthodes traitant sur des applications plus avancées.\n",
    "\n",
    "## Segmentation d'image\n",
    "\n",
    "Bien qu'il soit pratique de pouvoir classifier une image, il est encore plus pratique de pouvoir classifier quelle partie de l'image contient la catégorie en question par pixel. Il s'agit de la segmentation d'image. Un exemple populaire est l'algorithme [Mask R-CNN](https://arxiv.org/abs/1703.06870). Vous pouvez trouver un tutoriel sur l'implémentation de cet algorithme [ici].(https://github.com/matterport/Mask_RCNN/blob/master/samples/shapes/train_shapes.ipynb)\n",
    "\n",
    "Voici un exemple d'image segmentée par catégrorie:\n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/detection_final.png?raw=true)\n",
    "\n",
    "\n",
    "## Modèles génératifs (exemple des GANs)\n",
    "\n",
    "Un GAN consiste de deux réseaux qui se font concurrence. Ils ont pour but de se surpasser l'un l'autre. Un réseau génère des images fictives et tente de convaincre l'autre réseau du réalisme de l'image tandis que l'autre réseau est entrainé à discerner une vraie image d'une fausse. Ceci permet la générations d'images réalistes lorsque les deux réseaux sont bien entrainés. Vous pouvez trouver la publication originale [ici](http://papers.nips.cc/paper/5423-generative-adversarial-nets) ainsi qu'une implémentation [ici](https://github.com/diegoalejogm/gans)\n",
    "\n",
    "Voici un exemple de GAN sur MNIST: \n",
    "\n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/CNN/images/1_nAVqFluPijpBWR2tI4gCxg.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsLwCjnbWkk4"
   },
   "source": [
    "# Références\n",
    "Certaines parties de ce tutoriel sont fortement inspirées des tutoriaux suivant :\n",
    "<ul>\n",
    "<li>https://github.com/andrewliao11/dni.pytorch/blob/master/mlp.py\n",
    "<li>https://github.com/andrewliao11/dni.pytorch/blob/master/cnn.py\n",
    "<li>http://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "<li>http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    " <li>http://cs231n.github.io/convolutional-networks/\n",
    " <li>http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#convolution-as-a-matrix-operation\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_a_completer.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
