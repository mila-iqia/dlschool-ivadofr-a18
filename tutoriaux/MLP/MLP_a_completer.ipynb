{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mipSoOVlavkb"
   },
   "source": [
    "# ÉCOLE IVADO/MILA EN APPRENTISSAGE PROFOND\n",
    "# SESSION D' AUTOMNE 2018 \n",
    "# Tutoriel : Données Catégorielles (MLP)\n",
    "\n",
    "## Auteurs: \n",
    "\n",
    "Arsène Fansi Tchango <arsene.fansi.tchango@rd.mila.quebec>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLHwvggEZERd"
   },
   "source": [
    "## Préface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JKNGtQkkohiM"
   },
   "source": [
    "Ce tutoriel a pour but d'initier les participants aux aspects pratiques du Deep Learning  à travers la réalisation d'un projet simple de bout en bout. Dans le cadre de cet exercice, nous utiliserons le framework de développement <a href=\"https://pytorch.org/\"> `PyTorch`</a>. Celui-ci a été choisie pour sa souplesse et sa flexibilité qui ont pour effet bénéfique de rendre la courbe d'apprentissage du framework facile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NOD70vdvvtin"
   },
   "source": [
    "# Initialisation\n",
    "\n",
    "Avant de commencer, nous devons nous assurer d'installer les librairies nécessaires pour le tutoriel à l'aide de `pip`.  Pour se faire, exécutez la cellufle suivante en la sélectionnant et en cliquant `shift`+`Enter`. Ceci peut prendre quelques minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 51918,
     "status": "ok",
     "timestamp": 1539775182153,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "c5AlBPjnvzNh",
    "outputId": "25af9e31-6ed4-41a9-a3de-c4d933cbb426"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision Pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "djF9gjzLwsDB"
   },
   "source": [
    "Afin de vous assurer que l'installation s'est bien faite, importez toutes les libraries et modules dont nous nous servirons pour ce tutoriel en exécutant la prochaine cellule:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6776,
     "status": "ok",
     "timestamp": 1539775410716,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "w9LnNnxBw0wC",
    "outputId": "d4f1b1a5-583e-4c19-d1c4-825187f8c482"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "print(\"Torch version: \", torch.__version__)\n",
    "print(\"GPU Available: {}\".format(use_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU ou GPU\n",
    "**Rappel:** <a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> est une librairie qui permet d'utiliser des GPUs pour effectuer les calculs sur des tenseurs. La librairie inclus des tenseurs de type CUDA qui ont les mêmes fonctions que les tenseurs réguliers mais qui utilisent des GPUs pour leurs calculs, au lieu d'un CPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> retourne un booléen indiquant si CUDA est présentement disponible. Pour passer d'un tenseur de type CPU à un tenseur de type GPU, il suffit de lui ajouter `.cuda()`.\n",
    "\n",
    "Pour plus d'informations sur comment utiliser les GPU sur colab, vous pouvez lire ce [tutoriel](https://colab.research.google.com/drive/1y3ZE4m-D7lPoMzsypSEXessYmjWfKGqD#scrollTo=3IEVK-KFxi5Z).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZKzgFV9Favkt"
   },
   "source": [
    "## PyTorch en bref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vrus_-F0avkt"
   },
   "source": [
    "*PyTorch* est une librairie Python qui fournit deux fonctionnalités de haut niveau:\n",
    "<ul>\n",
    "<li> Opérations sur des tenseurs (comme NumPy) avec support GPU </li>\n",
    "<li> Réseaux de neurones profonds construits sur un système de <b> différentiation automatique</b> appelé  <b> <a href=\"http://pytorch.org/docs/master/autograd.html\">Autograd:  `torch.autograd`</a> </b>.</li>\n",
    "</ul>\n",
    "<br/>\n",
    "Voici les documentations utiles relatives à ce sujet: \n",
    "<ul>\n",
    "<li>  La documentation principale sur PyTorch: <a href=\"http://pytorch.org/docs/master/torch.html\"> `Docs - PyTorch` .</a> </li>\n",
    "<li>  La documentation principale  sur les réseaux de neurones: <a href=\"http://pytorch.org/docs/master/nn.html\">`torch.nn`</a>. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7oPl95cswjd"
   },
   "source": [
    "En plus d'offrir des facilités pour définir et manipuler les réseaux de neuronnes, PyTorch offre plusieurs utilitaires pour le traitement des données. \n",
    "<br/> \n",
    "Un de ces utilitaires est la classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> </b> et ses sous-classes (`torch.utils.data.TensorDataset`, `torch.utils.data.Subset`, `etc...`) qui offrent une interface facile d'utilisation pour manipuler un jeu de données.\n",
    "<br/>\n",
    "Pour plus d'informations, veuillez vous reportez aux urls suivantes: \n",
    "<ul>\n",
    "<li>Les jeux de données en PyTorch: <a href=\"http://pytorch.org/docs/master/data.html\"> `Datasets - PyTorch` .</a>  </li>\n",
    "<li>Un tutoriel pour le chargement des données: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> `Data Loading Tutorial - PyTorch` .</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qm122vNmq92L"
   },
   "source": [
    "## Elements nécessaires pour un projet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqvhR0ebavmE"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Pour mener à bien un projet en deep learning, on a besoin de:\n",
    "<ul>\n",
    "<li>Une <b> tâche à résoudre</b> ainsi que des <b>données</b> pour la supporter </li>\n",
    "<li>Un <b>modèle</b> (réseau de neurones) à entraîner </li>\n",
    "<li>Une <b>fonction de coût</b> à optimiser </li>\n",
    "<li>Un <b>optimiseur</b> qui ajustera les paramètres (poids) du réseau de neurones</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8_pfpu2f6AO"
   },
   "source": [
    "# DÉFINITION DE LA TÂCHE:  Prédiction de la survie suite à un naufrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B5piZxYUhSzq"
   },
   "source": [
    "Notre objectif est de <b>prédire si un passager a survécu ou non suite au naufrage du Titanic</b> en se basant sur des données obtenues sur les passagers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4GuYNDFavlU"
   },
   "source": [
    "## Le dataset Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NiOJx2ytavlU"
   },
   "source": [
    "Le jeu de données Titanic peut être téléchargé à l'adresse suivante:  https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/>\n",
    "Cet ensemble de données fournit des informations sur le sort de 1309 passagers du premier voyage fatal du paquebot \"Titanic\", résumées par <br/>\n",
    "statut économique (classe), sexe, âge, les informations familiales et survie. Cet ensembles de données est  également celui utilisé par le <br/>\n",
    "concours Kaggle et permet ainsi de réduire  la barrière à l'entrée pour les utilisateurs débutants en apprentissage machine.\n",
    "\n",
    "\n",
    "Nous utiliserons la librarire <a href=\"https://pandas.pydata.org/\"> <b> Pandas </b></a>   pour charger en mémoire le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1539775895941,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "bX_RSiffavlW",
    "outputId": "310823e7-36c6-466b-8c2a-ba96fdcb20de"
   },
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
    "    sep='\\t', \n",
    "    index_col=None, \n",
    "    na_values=['NA']\n",
    ")\n",
    "\n",
    "# Un appeçu des données\n",
    "\n",
    "titanic_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj88WmCmavlf"
   },
   "source": [
    "**La signification des différentes colonnes (features) est la suivante**:\n",
    "\n",
    "<ol>\n",
    "\n",
    "  <li> <b>pclass</b>: Classe du Passager (1 = première; 2 = seconde; 3 = troisième) </li>\n",
    "  <li> <b>survived</b>: Survie (0 = non; 1 = oui) </li>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, sœurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou enfants à bord </li>\n",
    "  <li> <b>ticket</b>: Numéro de ticket </li>\n",
    "  <li> <b>fare</b>: Tarif passager </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
    "  <li> <b>boat</b>: Canot de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro de corps (si le passager n'a pas survécu et que son corps a été retrouvé) </li>\n",
    "  <li> <b>home.dest</b>: la destination du passager </li>\n",
    " </ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2ed5fozqjce"
   },
   "source": [
    "## Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__vcZhPnavlg"
   },
   "source": [
    "Certaines données sont **moins importantes** que d'autres, par exemple:\n",
    "<ol>\n",
    "  <li> <b>name</b>: Nom </li>\n",
    "  <li> <b>ticket</b>: Numéro de ticket </li>\n",
    "  <li> <b>cabin</b>: Numéro de cabine </li>\n",
    "  <li> <b>home.dest</b>: la destination du passager </li>\n",
    " </ol>\n",
    " \n",
    "\n",
    "\n",
    "D'autres données sont **fortement** correlées à notre tâche, et les inclure reviendrait à **tricher**:\n",
    "<ol>\n",
    "  <li> <b>boat</b>: Canot de sauvetage (si le passager a survécu) </li>\n",
    "  <li> <b>body</b>: Numéro de corps (si le passager n'a pas survécu et que son corps a été retrouvé) </li>\n",
    " </ol>\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "Par ailleurs, nous remarquons la présence des features de type **variables catégorielles**, il faut les transformer en données numériques avec de l'<a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">**encodage one-hot**</a>:\n",
    " <ol>\n",
    "  <li> <b>pclass</b>: Classe du Passager </li>\n",
    "  <li> <b>sex</b>: Sexe </li>\n",
    "  <li> <b>embarked</b>: Port d'embarquement </li>\n",
    " </ol>  \n",
    "  <br/>\n",
    " **Remarque:** La colonne <b>pclass</b> est apparemment numérique. Toutefois, cette représentation induit implicitement un biais. En effet, numériquement parlant, nous avons 1 (première classe) < 2 (secode classe) < 3 (troisième classe). On aurait pu multiplier cette colonne par `-1` pour réfléter notre société mais nous avons opté de rester neutre. \n",
    " <br/>\n",
    " <br/>\n",
    " \n",
    " Le dataset pré-processé peut être téléchargé à l'adresse suivante:  https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true. \n",
    " La signification des variables est la suivante:\n",
    "\n",
    "<ol>\n",
    "  <li> <b>survived</b>: Survie (0 = non; 1 = oui) </li>\n",
    "  <li> <b>pclass_1</b>: (1 si passager en première classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_2</b>: (1 si passager en seconde classe; 0 sinon) </li>\n",
    "  <li> <b>pclass_3</b>: (1 si passager en troisième classe; 0 sinon) </li>\n",
    "  <li> <b>sex_female</b>: (1 si passager est une femme; 0 sinon) </li>\n",
    "  <li> <b>sex_male</b>: (1 si passager est un homme; 0 sinon) </li>\n",
    "  <li> <b>age</b>: Âge </li>\n",
    "  <li> <b>sibsp</b>: Nombre de frères, sœurs, ou conjoints à bord </li>\n",
    "  <li> <b>parch</b>: Nombre de parents ou enfants à bord </li>\n",
    "  <li> <b>fare</b>: Tarif passager </li>\n",
    "  <li> <b>embarked_C</b>: (1 si Port d'embarquement = Cherbourg (C); 0 sinon) </li> \n",
    "  <li> <b>embarked_Q</b>: (1 si Port d'embarquement = Queenstown (Q); 0 sinon) </li> \n",
    "  <li> <b>embarked_S</b>: (1 si Port d'embarquement = Southampton (S); 0 sinon)</li> \n",
    " </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 949,
     "status": "ok",
     "timestamp": 1539776190414,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "JJ0--SDpavlg",
    "outputId": "fe08ba4d-d829-4835-b91f-f87d71e3f6e3"
   },
   "outputs": [],
   "source": [
    "titanic_preprocess_df = pd.read_csv(\n",
    "    'https://github.com/afansi/winterschool18/blob/master/titanic_prepocess.csv?raw=true', \n",
    "    sep=',', \n",
    "    index_col=None\n",
    ")\n",
    "\n",
    "titanic_preprocess_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJcs6PUTavlm"
   },
   "source": [
    "## Découpage en Train / Validation / Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bjbgvffmavlo"
   },
   "source": [
    "Lorsque celà n'a pas déjà été fait,  le dataset est divisé en trois parties:\n",
    "\n",
    "<ol>\n",
    "<li> <b> Train</b> (en général, 60 % du dataset): utilisée pour entraîner le modèle de classification.</li>   \n",
    "<li> <b> Validation</b> (en général, 20 % du dataset): utilisée pour évaluer les performances du modèle en cours d'entraînement.</li>   \n",
    "<li> <b> Test</b> (en général, 20 % du dataset): utilisée pour évaluer les performances de généralisation du modèle entraîné. </li>\n",
    "</ol>\n",
    "\n",
    "Nous utilisons la fonction [np.split](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.split.html) afin de séparer notre jeu de données en sous-ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GBmL8VBOavlo"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "train, validate, test = np.split(\n",
    "    titanic_preprocess_df.sample(frac=1, random_state=134), \n",
    "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
    "\n",
    "X_train = train.drop(['survived'], axis=1).values\n",
    "y_train = train['survived'].values\n",
    "\n",
    "# À compléter \n",
    "X_val = ...\n",
    "y_val = ...\n",
    "\n",
    "X_test = ...\n",
    "y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wv74TbIWavlr"
   },
   "source": [
    "## Datasets en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9_LJtG-Xavlt"
   },
   "source": [
    "Nous utiliserons la sous-classe <b><a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.TensorDataset`</a> </b> qui permet d'encapsuler ensemble les features et la target d'un jeu de données. Nous encapsulerons les données de Train, Validation, et Test définies dans la section précédente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1JtT4tV7avlt"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "\n",
    "# À compléter \n",
    "\n",
    "val_dataset = ...\n",
    "\n",
    "test_dataset = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obEPHnlTavkc"
   },
   "source": [
    "# Définition du modèle: Perceptron Multi-couche (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhN5GL6Gavks"
   },
   "source": [
    "\n",
    "Un perceptron multi-couche est un réseau de neurones à propagation avant. Il prend en entrée les données à traiter, les transforme à travers une série de couches cachées et renvoie une prédiction en sortie.\n",
    "\n",
    "La procédure d'apprentissage typique pour ce modèle consiste en :\n",
    "<ul>\n",
    "<li>Définir l'architecture du réseau. Cela définira les paramètres (non-linéarités, nombre de poids et biais) du réseau.</li>\n",
    "<li>Définir la fonction de coût et l'optimiseur.</li>\n",
    "<li>Entraîner le réseau.</li>\n",
    "<li>Tester le réseau.</li>\n",
    "</ul>\n",
    "\n",
    "Pour résoudre notre tâche, nous allons utiliser un MLP avec les caractéristiques suivantes:\n",
    " <ul>\n",
    " <li> <b> 4 </b> **couches** (<b> 3 </b> couches cachées et <b> 1 </b> couche de sortie) </li>\n",
    " <li> la **dimension** des données d'**entrées** est de <b> 12 . </b></li>\n",
    " <li> les dimensions des différentes **couches intermédiaires** sont <b> 20, 40, 20, 2. </b> </li>\n",
    " <li> utilisation de la fonction d'activation <b> ReLu </b> pour les 3 couches cachées.</li>\n",
    " </ul>\n",
    " \n",
    " Voici un exemple d'architecture que nous allons utiliser: \n",
    " \n",
    "![Alt Text](https://github.com/mila-iqia/ecole_dl_mila_ivado/blob/master/tutoriaux/MLP/images/figures_tuto.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "701t0e-ravkr"
   },
   "source": [
    "## Implémentation du modèle en PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgtCculMavku"
   },
   "source": [
    "### 1 - Boîte à outils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4F5cyijavkv"
   },
   "source": [
    "<ul>\n",
    "<li> La classe <b><a href=\"http://pytorch.org/docs/master/nn.html#module\">`torch.nn.Module`</a></b>: \n",
    "\n",
    "    <br/> En PyTorch, tout réseau de neurones doit <b>hériter</b> de cette classe ou de ses descendantes (sous-classes).\n",
    "    <br/> \n",
    "</li>   \n",
    "<li> La méthode <b>`forward` (...)</b>: \n",
    "    <br/> Toute classe définissant un réseau de neurones doit <b>implémenter</b> la méthode  `forward(...)`. C'est cette méthode qui définit les opérations effectuées par le réseau de neurones et, le cas échéant, construit le graphe computationnel correspondant.\n",
    "    <br/> \n",
    "</li>  \n",
    "<li> La classe <b><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a></b>: \n",
    "    <br/> Cette classe implémente <b>une couche de réseau dense</b> sans fonction d'activation à sa sortie. <br/> Elle prend par défaut deux paramètres: \n",
    "    <ul>\n",
    "    <li><b>`in_features`</b>: la dimension des données en entrée de la couche. </li>\n",
    "    <li><b>`out_features`</b>: la dimension des données en sortie de la couche. </li>    \n",
    "    </ul>\n",
    "    \n",
    "</li>\n",
    "<li> Le module <b><a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`torch.nn.functional`</a></b>: \n",
    "<br/> Il définit un ensemble de fonctions qui peuvent être appliquées aux sorties des différentes composantes d'un réseau de neurones. On y retrouve par example:\n",
    "    <ul>\n",
    "    <li> des fonctions non-lineaires: <b><a href=\"http://pytorch.org/docs/master/nn.html#id36\">`sigmoid(...)`</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#id35\">`tanh(...)`</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#id22\">`relu(...)`</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#non-linear-activation-functions\">`etc...`</a> </li> \n",
    "    <li> des fonctions de coûts: <b><a href=\"http://pytorch.org/docs/master/nn.html#mse-loss\">`mse_loss(...)`</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#nll-loss\">`nll(...)`</a></b>, <b><a href=\"http://pytorch.org/docs/master/nn.html#cross-entropy\">`cross_entropy(...)`</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#id42\">`etc ...`</a> </li> \n",
    "    <li> des fonctions de régularisation: <b><a href=\"http://pytorch.org/docs/master/nn.html#id38\">`droupout(...)`</a></b>, <a href=\"http://pytorch.org/docs/master/nn.html#dropout-functions\">`etc ...`</a>  </li> \n",
    "    <li> et <a href=\"http://pytorch.org/docs/master/nn.html#torch-nn-functional\">`plein d'autres encore ...`</a> </li> \n",
    "    </ul>\n",
    "    <br/> \n",
    "</li>\n",
    "</ul>\n",
    "\n",
    " les méthodes suivantes sont à compléter :\n",
    "<ul>\n",
    "<li>La méthode `__init__` qui définit les couches. </li>\n",
    "<li>La méthode `forward(input)` qui retourne l'`output`.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DMn6-Jepavkw"
   },
   "source": [
    "### 2 - Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NyQGwC-avkw"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "seed = 1234\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR5eBfIbavk0"
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(12, 20)\n",
    "        # À compléter\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # À Compléter\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OvLnHRZ5avk2"
   },
   "source": [
    "## Exécution d'un réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEXgJMDDavk3"
   },
   "source": [
    "\n",
    "Dans cette section, nous exécuterons notre réseau de neurones sur des données aloitoirement générées. \n",
    "\n",
    "### 1 - Boîte à outils\n",
    "<b>Important à savoir:</b>\n",
    "    En PyTorch, il existe deux modes d'exécution d'un réseau de neurones:\n",
    "    <ul>\n",
    "    <li> <b>train</b>: dans ce mode, tous les mécanismes d'apprentissage (construction du graphe computationnel, auto-différentiation) sont mis en place à chaque exécution du réseau. Il est utilisé lorsque le réseau est en cours d'entraînement.</li>\n",
    "    <li> <b>eval</b>: dans ce mode, le modèle est en mode <b>inférence</b>. Il est utilisé lorsque le réseau est en cours d'évaluation.</li>\n",
    "    </ul>\n",
    "<br/>    \n",
    "Nous utiliserons le mode <b>eval</b> dans cette section.\n",
    "\n",
    "\n",
    "Afin de transformer nos prédictions en probailités, nous utiliserons aussi la fonction Softmax().\n",
    "\n",
    "<li><a href=\"http://pytorch.org/docs/master/nn.html#torch.nn.Softmax\">torch.nn.Softmax()</a> qui applique la fonction Sofmax à un tenseur d'entrée à n-dimension en le normalisant de tel sorte que les éléments de tenseur de sortie à n-dimension soient dans l'intervalle [0, 1] et somment à 1.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpaZwOVENm5q"
   },
   "source": [
    "### 2 - Implémentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1539777095652,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "gzcABMezavk6",
    "outputId": "0634cf28-4070-42ac-8629-e4d61c2774ea"
   },
   "outputs": [],
   "source": [
    "# Instantiation du réseau\n",
    "neural_net = NeuralNet()\n",
    "\n",
    "# activation du mode eval\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélection des 5 premières données du dataset de validation\n",
    "data, target = val_dataset[0:5]\n",
    "\n",
    "# Execution du réseau de neurones\n",
    "output = neural_net(data)   # ou, en version longue, neural_net.forward(data)\n",
    "\n",
    "# Tranformation des resultat en probabilités en utilisant la fonction SOFTMAX\n",
    "\n",
    "# À compléter \n",
    "output_proba = ...\n",
    "\n",
    "# Affichage des probabilités\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVep0BElavlS"
   },
   "source": [
    "Les lignes définissent la sortie du réseau, en terme de <b> probabilités sur deux classes</b>, <b>mort</b> (première colonne) ou <b>survie</b> (deuxième colonne), pour chacune des 5 données en entrée. Prenons le maximum de chaque prédiction comme la prédition de notre modèle et comparons les aux données réelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1539777281397,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "_jV4No36qjdU",
    "outputId": "de321e17-8907-44bc-c487-2d7de8123dd1"
   },
   "outputs": [],
   "source": [
    "# Affichage des prédictions (classe ayant la plus grande probabilités)\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print(\"Prédiction du modèle\")\n",
    "print(prediction)\n",
    "\n",
    "# Affichage de la vrai target\n",
    "print(\"Données réelles\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEIIjqOuqjdc"
   },
   "source": [
    "### 3 - Questions: \n",
    "\n",
    "<b> Comment performe notre modèle?</b> <br/>\n",
    "<b> Quelle serait une bonne manière de définir la performance? </b><br/>\n",
    "<b>Comment pouvons-nous améliorer notre modèle?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uySA2TCavmD"
   },
   "source": [
    "# Définir la fonction de coût et l'optimiseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkoobCLMavmE"
   },
   "source": [
    "## Fonction de coût"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qkX7uSXQavmF"
   },
   "source": [
    "La fonction de coût doit être définie en fonction de la tâche que nous souhaitons réaliser.\n",
    "\n",
    "PyTorch offre <a href=\"http://pytorch.org/docs/master/nn.html#id42\">une multitude de fonctions de coûts</a> prêtes à l'emploi.\n",
    "\n",
    "Pour des problèmes de classification, la fonction de coût usuelle est <b> l'entropie croisée (cross-entropy)</b> et c'est elle que nous allons utiliser dans ce tutoriel. En PyTorch, elle est définie par la fonction <b><a href=\"http://pytorch.org/docs/master/nn.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a></b>.  L'entropie croisée est souvent utilisée en optimisation. Elle permet de comparer une distribution $p$ avec une distibution de référence $t$. Elle est minimum lorsque $t=p$. Sa formule pour la calculer entre la prédiction et la cible est : $-\\sum_j t_{ij} \\log(p_{ij})$ où $p$ est la prédiction, $t$ la cible, $i$ les exemples et $j$ les classes de la cible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47Nvf8IhYn2b"
   },
   "source": [
    "**Implémentation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHnfYeS5avmF"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# À compléter \n",
    "\n",
    "def cost_function(prediction, target):\n",
    "    loss = ...\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vsx_cv9Wqjdj"
   },
   "source": [
    "## Rétro-propagation du gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hcZaIKtavmH"
   },
   "source": [
    "En Pytorch, grâce au mécanisme de differentiation automatique <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, il est possible de calculer automatiquement le gradient de la fonction de coût et de le rétro-propager à travers le graphe computationnel.\n",
    "\n",
    "Pour ce faire, une fois la fonction de coût calculée et stockée dans une variable, il suffit d'appeler la méthode <b> backward() </b> de cette dernière.<br/>\n",
    "<br/>\n",
    "\n",
    "**Snippet de rétro-propagation:**\n",
    "\n",
    "loss = fonction_de_cout(...) <br/>\n",
    "loss.backward()<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8YNo_ymYavmH"
   },
   "source": [
    "## Optimiseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4AlX9TwavmH"
   },
   "source": [
    "PyTorch fournit un <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">ensemble de méthodes d'optimisation (`torch.optim`)</a> couramment utilisées dans la communauté de Deep Learning. Parmi ces méthodes, on y retrouve notamment: \n",
    "<ul>\n",
    "<li><b>SGD</b> (Stochastic Gradient Descent) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a> qui est une implémentation de SGD.</li>\n",
    "<li><b>Adam</b> (Adaptive Moment Estimation): variante de la méthode de descente de gradient dans laquelle le taux d'apprentissage est ajusté pour chaque paramètre. Cet ajustement est basé sur le momentum (moyenne glissante des gradients) et la courbure (moyenne glissante de la dérivée seconde). Cet optimiseur a démontré de très bonnes performamces par rapport à SGD dans la litérature.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uam-a0_0qjdl"
   },
   "source": [
    "\n",
    "Pour pouvoir utiliser un optimiseur en PyTorch, il faut l'instancier en lui passant les éléments suivants:\n",
    "<ul>\n",
    "<li><b>Les paramètres du réseau de neurones</b>: ceux-ci s'obtiennent à l'aide de la methode <b>parameters()</b> sur le modèle instanciée.</li>\n",
    "<li><b>Le taux d'apprentissage (learning rate, lr)</b>: c'est le taux d'apprentissage à utiliser pour la mise à jour des paramètres du réseau de neurones pendant le processus d'optimization.</li>\n",
    "<li>Il peut y avoir d'autres paramètres propres à l'optimiseur choisi</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt6_Qr6ravmI"
   },
   "source": [
    "PyTorch offre un interface simplifiée pour interagir avec tout optimiseur:\n",
    "<ul>\n",
    "<li><b>zero_grad()</b>: Permet d'effacer les gradients des paramètres du réseau de neurones à optimiser. Elle est appelée <b>au début d'une étape d'optimisation</b> afin de re-initialiser les infos sur les paramètres à optimiser. </li>\n",
    "<li><b>step()</b>: Permet d'effectuer une étape d'optimisation. Elle est appelée <b>après une étape de rétro-propagation du gradient</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZ-lKExqavmI"
   },
   "source": [
    "Dans ce tutoriel, nous utiliserons <b>Adam</b> avec une <b>lr</b> de 0.001."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVIyV9xY2at"
   },
   "source": [
    "**Implémentation: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDMOziJTavmI"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# À compléter \n",
    "\n",
    "optimizer = optim.Adam(...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnFOAfdGqjdr"
   },
   "source": [
    "# ENTRAÎNEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YD1paaYCavmJ"
   },
   "source": [
    "## Epoch, Itération, Mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0ksgXqwavmK"
   },
   "source": [
    "### 1- Définition \n",
    "<ol>\n",
    "<li>\n",
    "<b>Epoch</b> : une passe complète sur tout le dataset d'entraînement.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<b>Itération</b> : une mise à jour des paramètres du modèle (réseau de neurones). De nombreuses itérations peuvent se produire avant la fin d'un epoch.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<b>Mini-batch</b> : Sous-ensemble de données d'entrainement utilisées pour effectuer une mise à jour des paramètres du modèle. Autrement dit, à chaque itération, un mini-batch est utilisé. \n",
    "</li>\n",
    "\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLXjNiDTavmK"
   },
   "source": [
    "### 2 - Mini-batch en PyTorch \n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "PyTorch offre un utilitaire appelé <b><a href=\"http://pytorch.org/docs/master/data.html\"> torch.utils.data.DataLoader </a></b> permettant de charger un dataset quelconque et de le découper automatiquement en mini-batchs.\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6gjERhgavmL"
   },
   "source": [
    "**Bon à savoir**: \n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "Lors de l'entraînement, il est préférable que les données présentées au réseau apparaissent dans <b> un ordre différent d'un epoch à l'autre</b>.\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsQtU9ylavmL"
   },
   "source": [
    "### 3 - Implémentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7co1OxWJUMpL"
   },
   "source": [
    "Nous allons préparer les `DataLoader` pour nos trois ensembles de données (Entraînement, Validation, et Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGoQZSdqavmM"
   },
   "outputs": [],
   "source": [
    "train_batch_size = 32  # nombre de données dans un batch d'entraînement.\n",
    "test_batch_size = val_batch_size = 32   # nombre de données dans un batch d'évaluation.\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# À compléter \n",
    "\n",
    "val_loader = ...\n",
    "test_loader = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia3ai-GvavmP"
   },
   "source": [
    "## Boucle principale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCxQkQQjwuvq"
   },
   "source": [
    "### 1 - CPU ou GPU\n",
    "\n",
    "**Rappel:** <a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> est une fonction qui permet la prise en charge de tenseurs de types CUDA avec les mêmes fonctions que les tenseurs de types CPU mais utilisant pour le calcul des GPU. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> retourne un booléen indiquant si CUDA est présentement disponible. \n",
    "\n",
    "\n",
    "**Conseil:** Definir une variable `device` qui contient le device sur lequel vous souhaitez utiliser pour l'entrainement. Pour passer un tenseur ou un modèle sur le device en question, utiliser la methode `.to(device)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89u5gtjjymwP"
   },
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q11ZxpjxzHZm"
   },
   "source": [
    "### 2 - Implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9wNZrTnavmQ"
   },
   "source": [
    "Nous définissons ici notre procédure d'entraînement pour un epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyK9xCsZavmR"
   },
   "outputs": [],
   "source": [
    "def train(epoch, model, train_loader, optimizer, device):\n",
    "    \n",
    "    # mettre le modèle en mode train\n",
    "    model.train()\n",
    "    \n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    # Accumulateurs d'informations\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # itérer sur les batchs\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # Mettre les données sur le device\n",
    "        data, target = ...\n",
    "        \n",
    "        # mettre à zéro les gradients des paramètres du réseau de neurones\n",
    "        ...\n",
    "        \n",
    "        # exécuter le réseau de neurones sur les données du batch\n",
    "        prediction = ...\n",
    "        \n",
    "        # calculer la fonction de coût par rapport à la target\n",
    "        loss = cost_function(...)\n",
    "        \n",
    "        # faire la retro-propagation du gradient\n",
    "        ...\n",
    "        \n",
    "        # effectuer une étape d'optimisation\n",
    "        ...\n",
    "        \n",
    "        # effectuer la somme des coûts\n",
    "        total_loss += loss.item()*len(data)\n",
    "        \n",
    "        # calculer le nombre de bonnes prédictions (classe correspondante à la valeur maximale en sortie) \n",
    "        _, pred_classes = torch.max(prediction, dim=1)        \n",
    "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # calculer le coût moyen par epoch\n",
    "    mean_loss = total_loss/len(train_loader.dataset)\n",
    "    \n",
    "    # calculer l'acurracy\n",
    "    acc = correct / len(train_loader.dataset)\n",
    "        \n",
    "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
    "        100. * acc))   \n",
    "    \n",
    "    # retourner le coût moyen obtenu\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PxG666rmavmU"
   },
   "source": [
    "## Procédure d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGexbWaHavmU"
   },
   "source": [
    "Nous définissons ici notre procédure d'évaluation du modèle.\n",
    "<br/>\n",
    "En plus de passer le modèle en mode **eval**, il faut penser à désactiver le calcul du gradient (on n'en a pas besoin en mode inférence). <br/>\n",
    "Pour celà, PyTorch offre un ensemble de gestionnaires de contexte permettant de désactiver/activer localement le calcul du gradient:\n",
    "<ol>\n",
    "<li>\n",
    "<a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">`torch.no_grad()`</a>: désactiver le calcul du gradient.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">`torch.enable_grad()`</a>: activer le calcul du gradient.\n",
    "</li>\n",
    "\n",
    "<li>\n",
    "<a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">`torch.set_grad_enabled(bool)`</a>: activer/désactiver le calcul du gradient.\n",
    "</li>\n",
    "\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8gQj9W5LavmU"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, device):\n",
    "    \n",
    "    # mettre le modèle en mode eval\n",
    "    ...\n",
    "    \n",
    "    # Accumulateurs d'informations\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # itérer sur les batchs\n",
    "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
    "\n",
    "            # Mettre les données sur le device\n",
    "            data, target = ...\n",
    "\n",
    "            # exécuter le réseau de neurones sur les données du batch\n",
    "            prediction = ...\n",
    "\n",
    "            # calculer la fonction de coût par rapport à la target\n",
    "            loss = ...           \n",
    "\n",
    "\n",
    "            # effectuer la somme des coûts\n",
    "            total_loss += loss.item()*len(data)\n",
    "\n",
    "            # calculer le nombre de bonnes prédictions (classe correspondante à la valeur maximale en sortie)\n",
    "            _, pred_classes = torch.max(prediction, dim=1) \n",
    "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
    "          \n",
    "    \n",
    "    # calculer le coût moyen\n",
    "    mean_loss = total_loss/len(eval_loader.dataset)\n",
    "    \n",
    "    # calculer l'acurracy\n",
    "    acc = correct / len(eval_loader.dataset)\n",
    "        \n",
    "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
    "        mean_loss, correct, len(eval_loader.dataset),\n",
    "        100. * acc)) \n",
    "    \n",
    "    # retourner le coût moyen obtenu\n",
    "    return mean_loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMUyZNxdavmW"
   },
   "source": [
    "## Checkpointing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQLklQXAavmW"
   },
   "source": [
    "Pour des phases d'entraînement qui requièrent beaucoup de temps, il est recommandé de sauvegarder les paramètres (poids) du réseau de neurones au fil de l'apprentissage. C'est ce que l'on appelle communément le <b> checkpointing</b>.\n",
    "\n",
    "PyTorch offre <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">un mécanisme simple</a> pour effectuer cette opération. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld-Y2gF-avmX"
   },
   "source": [
    "Nous implémentons ici deux méthodes:\n",
    "<ul>\n",
    "<li> la première pour <b> sauvegarder </b> un réseau de neurones </li>\n",
    "<li> la seconde pour <b> charger </b> une sauvegarde de réseau de neurones </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMmNpma2avmX"
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, path='./'):\n",
    "    \n",
    "    # creation du nom de fichier indexé par la valeur de l'epoch\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # sauvegarde des paramètres du modèle.\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ZptgqQRavmZ"
   },
   "outputs": [],
   "source": [
    "def load_model(epoch, model, path='./'):\n",
    "    \n",
    "    # creation du nom de fichier indexé par la valeur de l'epoch\n",
    "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
    "    \n",
    "    # chargement des paramètres du modèle sauvegardé.\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ve8sOocWavma"
   },
   "source": [
    "**Important à savoir:**  \n",
    "\n",
    "Il est également possible de sauvegarder <b>l'état de l'optimiseur</b> en PyTorch. Ceci est très important dans les situations où nous souhaitons reprendre l'entraînement du réseau de neurones à partir d'une sauvegarde donnée. Pour plus d'informations, veuillez consulter l'url suivante: https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8lcAP8-1avma"
   },
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6902
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25128,
     "status": "ok",
     "timestamp": 1539780944582,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "keMpyePsavmb",
    "outputId": "25b1ebcc-c800-4077-b9dc-a74b5f89fede"
   },
   "outputs": [],
   "source": [
    "# nombre d'epochs\n",
    "numEpochs = 200\n",
    "\n",
    "# Frequence de sauvegarde\n",
    "checkpoint_freq = 10\n",
    "\n",
    "# Repertoire pour la sauvegarde des données\n",
    "path = './'\n",
    "\n",
    "# Accumulateurs des coûts moyens obtenu par epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Accumulateurs des performances par epoch\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Définition du réseau de neuronnes\n",
    "neural_net = ...\n",
    "\n",
    "# Mettre le réseau sur le device\n",
    "neural_net = ...\n",
    "\n",
    "# définition de l'optimiseur\n",
    "optimizer = ...\n",
    "\n",
    "# Itérer sur le nombre d'epochs\n",
    "for epoch in range(1, numEpochs + 1):\n",
    "    \n",
    "    # entraîner le modèle avec le dataset de train\n",
    "    train_loss, train_acc = train(...)   \n",
    "    \n",
    "    # évaluer le modèle avec le dataset de validation\n",
    "    val_loss, val_acc = evaluate(...)       \n",
    "    \n",
    "    # Sauvegarde des coûts obtenus\n",
    "    train_losses.append(train_loss)    \n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    # Sauvegarde des performamces\n",
    "    train_accuracies.append(train_acc)    \n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Checkpoint\n",
    "    if epoch % checkpoint_freq ==0:\n",
    "        save_model(...)\n",
    "\n",
    "# Sauvegarde du modèle à la fin de l'entraînement.\n",
    "save_model(...)\n",
    "    \n",
    "print(\"\\n\\n\\nOptimization ended.\\n\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86OZRLrjavmd"
   },
   "source": [
    "## Exécution du réseau de neurones avec des données réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1539781342192,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "mklvQruYavme",
    "outputId": "fe3c24b4-b92e-42d8-86c7-599e0276b724"
   },
   "outputs": [],
   "source": [
    "# activation du mode eval\n",
    "neural_net = neural_net.eval()\n",
    "\n",
    "# Sélection des 10 premières données du dataset de validation\n",
    "\n",
    "data, target = val_dataset[0:10]\n",
    "data = data.to(device)\n",
    "\n",
    "# Execution du réseau de neurones\n",
    "output = neural_net(data)   # ou, en version longue, neural_net.forward(data)\n",
    "\n",
    "# Tranformation des resultat en probabilités en utilisant la fonction SOFTMAX\n",
    "\n",
    "# À compléter \n",
    "\n",
    "output_proba = ...\n",
    "\n",
    "# Affichage des probabilités\n",
    "print(output_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1539781343276,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "RvIEqKt0qjeT",
    "outputId": "fcb08628-9247-4d8c-8a20-1282dfc2a79b"
   },
   "outputs": [],
   "source": [
    "# Affichage des prédictions (classe ayant la plus grande probabilités)\n",
    "_, prediction = torch.max(output_proba, dim=1)\n",
    "\n",
    "print(\"Prédiction du modèle\")\n",
    "print(prediction)\n",
    "\n",
    "# Affichage de la vrai target\n",
    "print(\"Données réelles\")\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V11J3Jihavmy"
   },
   "source": [
    "## Visualisation de la courbe d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9_9C_tXavmz"
   },
   "source": [
    "La <b>visualisation de la courbe d'apprentissage</b> permet de détecter d'éventuels problèmes survenus lors de l'apprentissage, par exemple, l'overfitting (sur-apprentissage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 500,
     "status": "ok",
     "timestamp": 1539781147825,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "iNcbpl0tavm0",
    "outputId": "cd28d35a-eaa2-4a68-fa98-72d7124bbb72"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = list(range(len(train_losses)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_losses, 'r', label=\"Train\")\n",
    "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
    "plt.title('Loss')\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=True, fancybox=True)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1539781152991,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "g-VGQ2pMavm4",
    "outputId": "fc84f290-8c6b-456e-8ba9-fa53f405dc0e"
   },
   "outputs": [],
   "source": [
    "x = list(range(len(train_accuracies)))\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(x, train_accuracies, 'r', label=\"Train\")\n",
    "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
    "plt.title('Accuracy')\n",
    "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
    "leg.get_frame().set_alpha(0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oktkpkuqjet"
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "<b> a) Que pouvez-vous dire de ces courbes ?  <br/>\n",
    "Illustrent-ils un régime de sur-apprentissage? Si non, pourquoi? Si oui, que pouvez-vous faire pour y remédier?</b> <br/>\n",
    "<b> b) Que pouvez-vous faire pour améliorer la performance du réseau de neurones sur des données de validation? </b><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XK_eUsq3avm8"
   },
   "source": [
    "# ÉVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UREO5elavm8"
   },
   "source": [
    "Nous pouvons finalement évaluer notre modèle apppris sur notre dataset de Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1539781169688,
     "user": {
      "displayName": "Jeremy Pinto",
      "photoUrl": "",
      "userId": "01769873812237395022"
     },
     "user_tz": 240
    },
    "id": "pPWvDM-qavm8",
    "outputId": "1a81293b-75e5-4b3b-b61d-17518a6e9017"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvP_-KUwqjez"
   },
   "source": [
    "**Questions:**\n",
    "\n",
    "<b> a) Comparer les résultats de validation et de test ?  Le réseau appris généralise t'il aussi bien qu'espéré ? <br/>\n",
    "b) Pensez-vous qu'il serait possible d'utiliser un MLP pour d'autres types de données, comme des images par exemple? </b> <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mgtCculMavku"
   ],
   "name": "MLP-AFT-Hiver18Tutorial-Complet.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
